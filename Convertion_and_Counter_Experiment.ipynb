{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from indic_transliteration import sanscript\n",
        "from indic_transliteration.sanscript import transliterate\n",
        "\n",
        "# Function to detect Hindi words more accurately\n",
        "def is_hindi_word(word):\n",
        "    # Define common Hindi characters and patterns\n",
        "    hindi_vowels = \"aāiīuūṛeēoōaiau\"\n",
        "    hindi_consonants = \"kghcjñṭḍnpbmśṣsṛḷvyh\"  # Basic consonant set\n",
        "    hindi_characters = hindi_vowels + hindi_consonants\n",
        "\n",
        "    # Check if the word contains at least 50% Hindi characters\n",
        "    hindi_char_count = sum(1 for char in word.lower() if char in hindi_characters)\n",
        "    return hindi_char_count > 0.5 * len(word)\n",
        "\n",
        "# Function to preprocess Hinglish text\n",
        "def preprocess_hinglish(hinglish_sentence):\n",
        "    words = hinglish_sentence.split()\n",
        "    processed_words = []\n",
        "\n",
        "    for word in words:\n",
        "        if is_hindi_word(word):  # If the word is likely Hindi in Latin script\n",
        "            try:\n",
        "                # Transliterate to Devanagari script\n",
        "                devanagari_word = transliterate(word, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
        "                processed_words.append(devanagari_word)\n",
        "            except Exception:\n",
        "                # If transliteration fails, keep the original word\n",
        "                processed_words.append(word)\n",
        "        else:\n",
        "            # Keep English words as they are\n",
        "            processed_words.append(word)\n",
        "\n",
        "    # Join back into a sentence\n",
        "    return \" \".join(processed_words)\n",
        "\n",
        "# Example Hinglish text\n",
        "hinglish_sentence = \"Mujhe coding karna pasand hai, aur machine learning mein interest hai.\"\n",
        "processed_sentence = preprocess_hinglish(hinglish_sentence)\n",
        "\n",
        "print(\"Original Sentence:\", hinglish_sentence)\n",
        "print(\"Processed Sentence:\", processed_sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ-RQ6Wqw9kh",
        "outputId": "369447b8-4222-4d4d-d1c4-242f6d8bccc6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence: Mujhe coding karna pasand hai, aur machine learning mein interest hai.\n",
            "Processed Sentence: ंउझे चोदिन्ग् कर्न पसन्द् है, और् मचिने लेअर्निन्ग् मेइन् इन्तेरेस्त् है।\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from indic_transliteration import sanscript\n",
        "from indic_transliteration.sanscript import transliterate\n",
        "\n",
        "# Improved function to preprocess Hinglish text\n",
        "def preprocess_hinglish(hinglish_sentence):\n",
        "    def clean_word(word):\n",
        "        # Normalize text: lowercase, strip punctuation, and fix common issues\n",
        "        word = word.lower()\n",
        "        word = word.strip(\".,!?\")  # Remove trailing punctuation\n",
        "        return word\n",
        "\n",
        "    words = hinglish_sentence.split()\n",
        "    processed_words = []\n",
        "\n",
        "    for word in words:\n",
        "        cleaned_word = clean_word(word)\n",
        "        try:\n",
        "            # Transliterate to Devanagari script\n",
        "            devanagari_word = transliterate(cleaned_word, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
        "            processed_words.append(devanagari_word)\n",
        "        except Exception:\n",
        "            # If transliteration fails, keep the original word\n",
        "            processed_words.append(cleaned_word)\n",
        "\n",
        "    # Join back into a sentence\n",
        "    return \" \".join(processed_words)\n",
        "\n",
        "# Example Hinglish text\n",
        "hinglish_sentence = \"Mujhe coding karna pasand hai, aur machine learning mein interest hai.\"\n",
        "processed_sentence = preprocess_hinglish(hinglish_sentence)\n",
        "\n",
        "print(\"Original Sentence:\", hinglish_sentence)\n",
        "print(\"Processed Sentence:\", processed_sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAcimcaFxSnB",
        "outputId": "c1a65471-4f71-4012-cd5a-fa68cb18b1db"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence: Mujhe coding karna pasand hai, aur machine learning mein interest hai.\n",
            "Processed Sentence: मुझे चोदिन्ग् कर्न पसन्द् है और् मचिने लेअर्निन्ग् मेइन् इन्तेरेस्त् है\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langdetect indic-transliteration"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJ2Z_-noyhFP",
        "outputId": "4cb6b761-abeb-47bd-a4cb-696080c97dd2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (1.0.9)\n",
            "Requirement already satisfied: indic-transliteration in /usr/local/lib/python3.10/dist-packages (2.3.68)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Requirement already satisfied: backports.functools-lru-cache in /usr/local/lib/python3.10/dist-packages (from indic-transliteration) (2.0.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from indic-transliteration) (2024.9.11)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.10/dist-packages (from indic-transliteration) (0.13.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from indic-transliteration) (0.10.2)\n",
            "Requirement already satisfied: roman in /usr/local/lib/python3.10/dist-packages (from indic-transliteration) (4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer->indic-transliteration) (8.1.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from typer->indic-transliteration) (4.12.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer->indic-transliteration) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer->indic-transliteration) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer->indic-transliteration) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer->indic-transliteration) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer->indic-transliteration) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langdetect import detect_langs\n",
        "from indic_transliteration import sanscript\n",
        "from indic_transliteration.sanscript import transliterate\n",
        "\n",
        "# Function to detect if the word is Hindi based on detection probability\n",
        "def is_hindi_word(word):\n",
        "    try:\n",
        "        # Detect the probabilities for multiple languages\n",
        "        lang_prob = detect_langs(word)\n",
        "\n",
        "        # If the probability for Hindi is higher than 0.5 (or any threshold you prefer)\n",
        "        if lang_prob.get('hi', 0) > 0.5:\n",
        "            return True\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        return False\n",
        "\n",
        "# Function to preprocess Hinglish text\n",
        "def preprocess_hinglish(hinglish_sentence):\n",
        "    words = hinglish_sentence.split()  # Tokenize sentence into words\n",
        "    processed_words = []\n",
        "\n",
        "    for word in words:\n",
        "        # Clean word of any trailing punctuation\n",
        "        cleaned_word = ''.join([char for char in word if char.isalnum() or char.isspace()])\n",
        "\n",
        "        # Check if the word is Hindi or English\n",
        "        if is_hindi_word(cleaned_word):  # If the word is detected as Hindi\n",
        "            # Transliterate Hindi words to Devanagari script\n",
        "            transliterated_word = transliterate(cleaned_word, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
        "            processed_words.append(transliterated_word)\n",
        "        else:\n",
        "            # Leave English words as they are\n",
        "            processed_words.append(word)\n",
        "\n",
        "    # Join the processed words back into a sentence\n",
        "    return \" \".join(processed_words)\n",
        "\n",
        "# Example Hinglish text\n",
        "hinglish_sentence = \"Mujhe coding karna pasand hai, aur machine learning mein interest hai.\"\n",
        "processed_sentence = preprocess_hinglish(hinglish_sentence)\n",
        "\n",
        "print(\"Original Sentence:\", hinglish_sentence)\n",
        "print(\"Processed Sentence:\", processed_sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFiyHoeWzEdn",
        "outputId": "9ce0fdc2-b157-40cd-8a2f-eba29b395aa4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence: Mujhe coding karna pasand hai, aur machine learning mein interest hai.\n",
            "Processed Sentence: Mujhe coding karna pasand hai, aur machine learning mein interest hai.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from indic_transliteration import sanscript\n",
        "from indic_transliteration.sanscript import transliterate\n",
        "\n",
        "# Predefined list of common Hindi words for this example\n",
        "hindi_words_set = set([\n",
        "    'mujhe', 'karna', 'pasand', 'hai', 'mein', 'aur', 'tum', 'kya', 'ho', 'kaise', 'sab', 'acha', 'jaldi', 'main'\n",
        "])\n",
        "\n",
        "# Function to preprocess Hinglish text\n",
        "def preprocess_hinglish(hinglish_sentence):\n",
        "    words = hinglish_sentence.split()  # Tokenize sentence into words\n",
        "    processed_words = []\n",
        "\n",
        "    for word in words:\n",
        "        cleaned_word = ''.join([char for char in word if char.isalnum()])  # Clean punctuation\n",
        "        if cleaned_word.lower() in hindi_words_set:\n",
        "            # Transliterate to Devanagari\n",
        "            transliterated_word = transliterate(cleaned_word, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
        "            processed_words.append(transliterated_word)\n",
        "        else:\n",
        "            # Keep English words as they are\n",
        "            processed_words.append(word)\n",
        "\n",
        "    # Join the processed words back into a sentence\n",
        "    return \" \".join(processed_words)\n",
        "\n",
        "# Example Hinglish text\n",
        "hinglish_sentence = \"Mujhe coding karna pasand hai, aur machine learning mein interest hai.\"\n",
        "processed_sentence = preprocess_hinglish(hinglish_sentence)\n",
        "\n",
        "print(\"Original Sentence:\", hinglish_sentence)\n",
        "print(\"Processed Sentence:\", processed_sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vocjOZ480BM4",
        "outputId": "cb3bdb2c-0cfd-4de1-9850-99d81a58cfd3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence: Mujhe coding karna pasand hai, aur machine learning mein interest hai.\n",
            "Processed Sentence: ंउझे coding कर्न पसन्द् है और् machine learning मेइन् interest है\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "# Predefined list of common Hindi words for this example\n",
        "hindi_words_set = set([\n",
        "    'mujhe', 'karna', 'pasand', 'hai', 'mein', 'aur', 'tum', 'kya', 'ho', 'kaise', 'sab', 'acha', 'jaldi', 'main'\n",
        "])\n",
        "\n",
        "# Function to count and categorize Hindi and English words\n",
        "def count_and_categorize_words(sentence):\n",
        "    # Tokenize the sentence into words\n",
        "    words = sentence.split()\n",
        "    hindi_count = 0\n",
        "    english_count = 0\n",
        "    hindi_words = []\n",
        "    english_words = []\n",
        "\n",
        "    # Iterate over each word\n",
        "    for word in words:\n",
        "        # Remove punctuation from the word\n",
        "        cleaned_word = word.strip(string.punctuation).lower()  # Clean punctuation and convert to lowercase\n",
        "\n",
        "        # Avoid empty words\n",
        "        if not cleaned_word:\n",
        "            continue\n",
        "\n",
        "        # Check if it's a Hindi word or an English word\n",
        "        if cleaned_word in hindi_words_set:\n",
        "            hindi_count += 1\n",
        "            hindi_words.append(word)  # Add original word with punctuation\n",
        "        else:\n",
        "            english_count += 1\n",
        "            english_words.append(word)  # Add original word with punctuation\n",
        "\n",
        "    return hindi_count, english_count, hindi_words, english_words\n",
        "\n",
        "# Example Hinglish text\n",
        "hinglish_sentence = \"Mujhe coding karna pasand hai, aur machine learning mein interest hai.\"\n",
        "hindi_count, english_count, hindi_words, english_words = count_and_categorize_words(hinglish_sentence)\n",
        "\n",
        "# Print results\n",
        "print(f\"Original Sentence: {hinglish_sentence}\")\n",
        "print(f\"Hindi Word Count: {hindi_count}\")\n",
        "print(f\"English Word Count: {english_count}\")\n",
        "print(f\"Hindi Words: {hindi_words}\")\n",
        "print(f\"English Words: {english_words}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjXFlBIn2wlu",
        "outputId": "649dd948-8ad0-4ca3-fd8c-ee95e111120b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence: Mujhe coding karna pasand hai, aur machine learning mein interest hai.\n",
            "Hindi Word Count: 7\n",
            "English Word Count: 4\n",
            "Hindi Words: ['Mujhe', 'karna', 'pasand', 'hai,', 'aur', 'mein', 'hai.']\n",
            "English Words: ['coding', 'machine', 'learning', 'interest']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kQa2bHxa4mmN"
      },
      "execution_count": 34,
      "outputs": []
    }
  ]
}